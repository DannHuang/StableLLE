model:
  base_learning_rate: 5.0e-5
  target: ldm.models.diffusion.ddpm.WaveletControlNet
  params:
    scale_factor: 0.18215
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    ckpt_path: /share/huangrenyuan/model_zoo/v2-1/v2-1_512-ema-pruned.ckpt
    first_stage_key: "image"
    cond_stage_key: "txt"
    freeze_unet: True
    image_size: 64
    channels: 4
    cond_stage_trainable: false
    conditioning_key: crossattn
    is_controlled: True
    monitor: val/loss_simple_ema
    use_ema: False

    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.ControlledUNet
      params:
        use_checkpoint: False
        use_fp16: False
        image_size: 384
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_head_channels: 64
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024
      
    control_model_config:
      target: ldm.modules.diffusionmodules.openaimodel.WaveletUNetEncoder
      params:
        image_size: 384
        use_checkpoint: False
        in_channels: 4
        model_channels: 320
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_head_channels: 64
        use_wavelet_transformer: False
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024   # no context MHA
        # spatial_transformer_attn_type: softmax-xformers

    cond_stage_config:
      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder
      params:
        freeze: True
        layer: "penultimate"
        arch: "ViT-H-14"
        version: /share/huangrenyuan/model_zoo/clip/open_clip_pytorch_model.bin

    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          #attn_type: "vanilla-xformers"
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

data:
  target: sgm.data.dataset.LDMDataModuleFromConfig
  params:
    batch_size: 6
    num_workers: 2

    train:
      # RealESRGAN dataset
      target: basicsr.data.paired_image_dataset.PairedImageDataset
      params:
        gt_size: 384
        org_prob: 0.1
        # dataset_prob: [0.2, 0.3, 0.3, 0.1, 0.1]
        dataset_configs:
        - root: /share/huangrenyuan/dataset/llie/LOL-v2/Synthetic/Train
          image_type: png
          mul_num: 4
          # num_pic: 12000
          # resize_range: [1024, 1280, 1536, 1792, 2048, 2304, 2560]
        - root: /share/huangrenyuan/dataset/llie/LSRW/Huawei
          image_type: jpg
        - root: /share/huangrenyuan/dataset/llie/LSRW/Nikon
          image_type: jpg
        crop_size: 384
        io_backend:
          type: disk

    validation:
      target: basicsr.data.paired_image_dataset.PairedImageDataset
      params:
        gt_size: 384
        org_prob: 1
        dataset_configs:
        - root: /share/huangrenyuan/dataset/llie/LOL-v2/Real_captured/Train
          image_type: png
          mul_num: 2
          filename_tmpl: "low{}"
        crop_size: 384
        io_backend:
          type: disk

lightning:
  modelcheckpoint:
    params:
      every_n_train_steps: 500
      save_top_k: 1
      save_last: False

  callbacks:
    # metrics_over_trainsteps_checkpoint:
    #   params:
    #     every_n_train_steps: 2500

    image_logger:
      target: main.ImageLogger
      params:
        disabled: True
        enable_autocast: False
        batch_frequency: 1000
        max_images: 4
        increase_log_steps: True
        log_first_step: True
        log_images_kwargs:
          use_ema_scope: False
          N: 3
          n_rows: 2

  trainer:
    benchmark: True
    strategy: ddp
    num_sanity_val_steps: 0
    accumulate_grad_batches: 4
    max_epochs: 1000